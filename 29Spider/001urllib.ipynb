{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "写入成功\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "# 1. 指定url\n",
    "url = 'https://www.sogou.com'\n",
    "\n",
    "# 2. 发起请求：urlopen可以根据指定的url发起请求，且返回一个响应对象\n",
    "resp = urllib.request.urlopen(url=url)\n",
    "\n",
    "# 3. 获取页面数据: read函数返回的就是相应对象中存储的页面数据(bytes)\n",
    "page_text = resp.read()\n",
    "\n",
    "# 4. 持久化存储\n",
    "with open('./src/sogou.html', mode='wb') as f:\n",
    "    f.write(page_text)\n",
    "    print('写入成功')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "写入成功\n"
     ]
    }
   ],
   "source": [
    "# 需求：爬取搜狗词条\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "\n",
    "url = 'https://www.sogou.com/web?query='\n",
    "# url特性：url不可以存在非ASCII编码的字符数据\n",
    "keyword = urllib.parse.quote('周杰伦')\n",
    "url +=  keyword\n",
    "\n",
    "resp = urllib.request.urlopen(url=url)\n",
    "page_text = resp.read()\n",
    "with open('./src/杰伦.html', mode='wb') as f:\n",
    "    f.write(page_text)\n",
    "    print('写入成功')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 反爬机制\n",
    "- User-Agent(UA): 请求载体的身份标识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "写入成功\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "\n",
    "url = 'https://www.sogou.com/web?query='\n",
    "keyword = urllib.parse.quote('周杰伦')\n",
    "url +=  keyword\n",
    "\n",
    "# UA伪装，需借助自定义请求对象\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36\"\n",
    "}\n",
    "request = urllib.request.Request(url=url, headers=headers)\n",
    "\n",
    "resp = urllib.request.urlopen(request)\n",
    "page_text = resp.read()\n",
    "with open('./src/杰伦.html', mode='wb') as f:\n",
    "    f.write(page_text)\n",
    "    print('写入成功')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- urllib模块发起的post请求\n",
    "- 实例：post请求百度翻译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "写入成功\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "\n",
    "# 指定url\n",
    "url = 'https://fanyi.baidu.com/sug'\n",
    "\n",
    "# post请求携带的参数进行处理, dict str bytex\n",
    "data = {\n",
    "    'kw': '西瓜'\n",
    "}\n",
    "data = urllib.parse.urlencode(data)\n",
    "data = data.encode()\n",
    "\n",
    "# 执行请求\n",
    "resp = urllib.request.urlopen(url=url, data=data)\n",
    "with open('./src/melon.json', mode='wb') as f:\n",
    "    f.write(resp.read())\n",
    "    print('写入成功')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### urllib高级用法\n",
    "- 代理\n",
    "- cookie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.parse\n",
    "\n",
    "# 1. 创建处理器对象，在其内部封装代理IP和端口\n",
    "handler = urllib.request.ProxyHandler(proxies={'http': '106.90.136.204:8123'})\n",
    "\n",
    "# 2. 创建opener对象，然后使用该对象发起一个请求\n",
    "opener = urllib.request.build_opener(handler)\n",
    "\n",
    "url='http://www.baidu.com/s?ie=UTF-8&wd=ip'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36',\n",
    "}\n",
    "request = urllib.request.Request(url, headers=headers)\n",
    "\n",
    "# 3. 使用opener对象发起请求\n",
    "resp = opener.open(request)\n",
    "with open('./src/proxy.html','wb') as fp:\n",
    "    fp.write(resp.read())\n",
    "    print('写入成功')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<urllib.request.HTTPCookieProcessor object at 0x0000027F79BF3EB8>\n"
     ]
    }
   ],
   "source": [
    "# cookjar使用\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import http.cookiejar\n",
    "\n",
    "cookie_jar = http.cookiejar.CookieJar()\n",
    "\n",
    "# 创建处理器对象(携带CookieJar对象)\n",
    "handler = urllib.request.HTTPCookieProcessor(cookie_jar)\n",
    "\n",
    "# 创建opener对象 （携带CookieJar对象）\n",
    "opener=urllib.request.build_opener(handler)\n",
    "\n",
    "data = {\n",
    "    \"payload\": \"xxxx\"\n",
    "}\n",
    "data=urllib.parse.urlencode(data).encode()\n",
    "request=urllib.request.Request(url,data=data)\n",
    "# 第一次请求\n",
    "opener.open(request)\n",
    "\n",
    "# opener会自动处理\n",
    "second_url = 'second_url'\n",
    "resp = opener.open(second_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
